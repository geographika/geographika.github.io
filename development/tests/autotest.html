<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Regression Testing &mdash; MapServer 7.0.0 documentation</title>
    
    <link rel="stylesheet" href="../../_static/sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '7.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../_static/mapserver.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="copyright" title="Copyright" href="../../copyright.html" />
    <link rel="top" title="MapServer 7.0.0 documentation" href="../../index.html" />
    <link rel="up" title="Testing" href="index.html" />
    <link rel="next" title="MapScript Unit Testing" href="mapscript.html" />
    <link rel="prev" title="Vagrant Usage" href="vagrant.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head>
  <body role="document">

<table width="100%" style="width: 100%; background-color: white;">
  <tr>
    <td rowspan="2" style="padding: 10px 0px 10px 10px;">
      <a href="../../index.html" title="Home"><img src="../../_static/banner.png" alt="MapServer banner" border="0" /></a>
    </td>
    <td style="padding: 10px 10px 0px 0px; text-align: right; vertical-align: top;">
      <a href="../../index.html" title="Home">Home</a> |
      <a href="../../products.html" title="Products (MapServer core, MapCache, TinyOWS">Products</a> |
      <a href="https://github.com/mapserver/mapserver/issues/" title="Issue Tracker (MapServer core)">Issue Tracker</a> |
      <a href="../../faq.html" title="FAQ">FAQ</a> |
      <a href="../../download.html" title="Download">Download </a>
    </td>
  </tr>
  <tr>
    <td style="padding: 0px 10px 0px 0px; text-align: right; vertical-align: bottom;">
        <img src="../../_static/flagicons/en.png" alt="en" title="en" border="0" width="18px" height="13px"/>
        
          <a href="../../de/development/tests/autotest.html"><img src="../../_static/flagicons/de.png" alt="de" title="de" border="0" /></a>
        
        
          <a href="../../es/development/tests/autotest.html"><img src="../../_static/flagicons/es.png" alt="es" title="es" border="0" /></a>
        
        
          <a href="../../zh_cn/development/tests/autotest.html"><img src="../../_static/flagicons/zh_cn.png" alt="zh_cn" title="zh_cn" border="0" /></a>
        

    </td>
  </tr>
</table>


    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="mapscript.html" title="MapScript Unit Testing"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="vagrant.html" title="Vagrant Usage"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Home</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Development</a> &raquo;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U">Testing</a> &raquo;</li> 
      </ul>
    </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="regression-testing">
<span id="autotest"></span><h1><a class="toc-backref" href="#table-of-contents">Regression Testing</a><a class="headerlink" href="#regression-testing" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Frank Warmerdam</td>
</tr>
<tr class="field-even field"><th class="field-name">Contact:</th><td class="field-body">warmerdam at pobox.com</td>
</tr>
<tr class="field-odd field"><th class="field-name">Last Updated:</th><td class="field-body">2015/2/13</td>
</tr>
</tbody>
</table>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first">Table of Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#regression-testing" id="id1">Regression Testing</a><ul>
<li><a class="reference internal" href="#getting-msautotest" id="id2">Getting <cite>msautotest</cite></a></li>
<li><a class="reference internal" href="#running-msautotest" id="id3">Running msautotest</a></li>
<li><a class="reference internal" href="#checking-failures" id="id4">Checking Failures</a></li>
<li><a class="reference internal" href="#background" id="id5">Background</a></li>
<li><a class="reference internal" href="#result-comparisons" id="id6">Result Comparisons</a></li>
<li><a class="reference internal" href="#requires-handling-build-options" id="id7">REQUIRES - Handling Build Options</a></li>
<li><a class="reference internal" href="#run-parms-tests-not-using-shp2img" id="id8">RUN_PARMS: Tests not using shp2img</a></li>
<li><a class="reference internal" href="#result-file-preprocessing" id="id9">Result File Preprocessing</a></li>
<li><a class="reference internal" href="#what-if-a-test-fails" id="id10">What If A Test Fails?</a></li>
<li><a class="reference internal" href="#todo" id="id11">TODO</a></li>
<li><a class="reference internal" href="#adding-new-tests" id="id12">Adding New Tests</a></li>
</ul>
</li>
</ul>
</div>
<p><cite>msautotest</cite> is a suite of test maps, data files, expected result images,
and test scripts intended to make it easy to run an a set of automated
regression tests on MapServer.</p>
<div class="section" id="getting-msautotest">
<h2><a class="toc-backref" href="#table-of-contents">Getting <cite>msautotest</cite></a><a class="headerlink" href="#getting-msautotest" title="Permalink to this headline">¶</a></h2>
<p>Skip this section if you&#8217;ve followed the <a class="reference internal" href="vagrant.html#vagrant"><span>Vagrant Usage</span></a> steps.</p>
<p><cite>msautotest</cite> is available from GitHub. On Unix it could be fetched
something like:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>git checkout https://github.com/mapserver/msautotest.git
</pre></div>
</div>
<p>This would create an <cite>msautotest</cite> subdirectory wherever you are. I normally put
the autotest within my MapServer directory.</p>
</div>
<div class="section" id="running-msautotest">
<h2><a class="toc-backref" href="#table-of-contents">Running msautotest</a><a class="headerlink" href="#running-msautotest" title="Permalink to this headline">¶</a></h2>
<p>If you&#8217;re using Vagrant as described in <a class="reference internal" href="vagrant.html#vagrant"><span>Vagrant Usage</span></a> everything is
installed and configured as needed and you may skip the next three
paragraphs.</p>
<p>The autotest requires python (but not python MapScript), so if you don&#8217;t have
python on your system - get and install it. More information on python is
available at <a class="reference external" href="http://www.python.org">http://www.python.org</a>. Most Linux system have some version
already installed.</p>
<p>The autotest also requires that the executables built with MapServer, notably
<a class="reference internal" href="../../utilities/shp2img.html#shp2img"><span>shp2img</span></a>, <a class="reference internal" href="../../utilities/legend.html#legend-utility"><span>legend</span></a>, <a class="reference internal" href="../../cgi/mapserv.html#mapserv"><span>mapserv</span></a> and
<a class="reference internal" href="../../utilities/scalebar.html#scalebar-utility"><span>scalebar</span></a>, are available in the path. I generally
accomplish this by adding the MapServer build directory to my path.</p>
<p>csh:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>% setenv PATH $HOME/mapserver:$PATH
</pre></div>
</div>
<p>bash/sh:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>% PATH=$HOME/mapserver:$PATH
</pre></div>
</div>
<p>Verify that you can run stuff by typing &#8216;shp2img -v&#8217; in the autotest
directory:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>warmerda@gdal2200[152]% shp2img -v
MapServer version 3.7 (development) OUTPUT=PNG OUTPUT=JPEG OUTPUT=WBMP
SUPPORTS=PROJ SUPPORTS=TTF SUPPORTS=WMS_SERVER SUPPORTS=GD2_RGB
INPUT=TIFF INPUT=EPPL7 INPUT=JPEG INPUT=OGR INPUT=GDAL INPUT=SHAPEFILE
</pre></div>
</div>
<p>Now you are ready to run the tests. The tests are subdivided into categories,
currently just &#8220;gdal&#8221;, &#8220;misc&#8221;, and &#8220;wxs&#8221; each as a subdirectory. To run the
&#8220;gdal&#8221; tests cd into the gdal directory and run the run_test.py script.</p>
<p>Unix:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>./run_test.py
</pre></div>
</div>
<p>Windows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>python.exe run_test.py
</pre></div>
</div>
<p>The results in the gdal directory might look something like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>warmerda@gdal2200[164]% run_test.py
version = MapServer version 6.0.0-beta2 OUTPUT=GIF OUTPUT=PNG OUTPUT=JPEG SUPPORTS=PROJ SUPPORTS=AGG SUPPORTS=FREETYPE SUPPORTS=ICONV SUPPORTS=WMS_SERVER SUPPORTS=WMS_CLIENT SUPPORTS=WFS_SERVER SUPPORTS=WCS_SERVER SUPPORTS=SOS_SERVER SUPPORTS=THREADS SUPPORTS=GEOS INPUT=POSTGIS INPUT=OGR INPUT=GDAL INPUT=SHAPEFILE

Processing: grayalpha.map
    results match.
Processing: class16.map
    result images match, though files differ.
Processing: nonsquare_multiraw.map
    results match.
Processing: bilinear_float.map
    results match.
Processing: processing_scale_auto.map
    results match.
Processing: grayalpha_plug.map
    result images match, though files differ.
Processing: processing_bands.map
    results match.
...
Processing: 256color_overdose_cmt.map
    results match.
Test done (100.00% success):
0 tested skipped
69 tests succeeded
0 tests failed
0 test results initialized
</pre></div>
</div>
<p>In general you are hoping to see that no tests failed.</p>
</div>
<div class="section" id="checking-failures">
<h2><a class="toc-backref" href="#table-of-contents">Checking Failures</a><a class="headerlink" href="#checking-failures" title="Permalink to this headline">¶</a></h2>
<p>Because most msautotest tests are comparing generated images to expected
images, the tests are very sensitive to subtle rounding differences on
different systems, and subtle rendering changes in libraries like freetype
gd, and agg. So it is quite common to see some failures.</p>
<p>These failures then need to be reviewed manually to see if the differences
are acceptable and just indicating differences in rounding/rendering or
whether they are &#8220;real&#8221; bugs. This is normally accomplished by visually
comparing files in the &#8220;result&#8221; directory with the corrresponding file in
the &#8220;expected&#8221; directory. It is best if this can be done in an application
that allows images to be layers, and toggled on and off to visually
highlight what is changing. OpenEV can be used for this.</p>
</div>
<div class="section" id="background">
<h2><a class="toc-backref" href="#table-of-contents">Background</a><a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>The msautotest suite was initially developed by Frank Warmerdam
(warmerdam at pobox.com), who can be contacted with questions it.</p>
<p>The msautotest suite is organized as a series of .map files. The python
scripts basically scan the directory in which they are run for files ending in
.map. They are then &#8220;run&#8221; with the result dumped into a file in the result
directory. A binary comparison is then done to the corresponding file in the
expected directory and differences are reported. The general principles for
the test suite are that:</p>
<ul class="simple">
<li>The test data should be small so it can be easily stored and checked out
without big files needing to be downloaded.</li>
<li>The test data should be completely contained within the test suite ... no
dependencies on external datasets, or databases that require additional
configuration. PostGIS and Oracle will require separate testing mechanisms.</li>
<li>The tests should be able to run without a significant deal of user
interaction. This is as distinct from the DNR test suite described in
FunctionalityDemo.</li>
<li>The testing mechanism should be suitable to test many detailed functions in
relative isolation.</li>
<li>The test suite is not dependent on any of the MapScript environments, though
I think it would be valuable to extend the testsuite with some mapscript
dependent components in the future (there is a start on this in the mspython
directory).</li>
</ul>
</div>
<div class="section" id="result-comparisons">
<h2><a class="toc-backref" href="#table-of-contents">Result Comparisons</a><a class="headerlink" href="#result-comparisons" title="Permalink to this headline">¶</a></h2>
<p>For shp2img tests The output files generated by processing a map is put in the
file results/&lt;mapfilebasename&gt;.png (regardless of whether it is PNG or not). So
when gdal/256_overlay_res.map is processed, the output file is written to
gdal/results/256_overlay_res.png. This is compared to
gdal/expected/256_overlay_res.png. If they differ the test fails, and the
&#8220;wrong&#8221; result file is left behind for investigation. If they match the result
file is deleted. If there is no corresponding expected file the results file
is moved to the expected directory (and reported as an &#8220;initialized&#8221; test)
ready to be committed to CVS.</p>
<p>For tests using RUN_PARMS, the output filename is specified in the RUN_PARMS
statement, but otherwise the comparisons are done similarly.</p>
<p>The initial comparison of files is done as a binary file comparison.  If
that fails, for image files, there is an attempt to compare the image checksums
using the GDAL Python bindings.  If the GDAL Python bindings are not available
this step is quietly skipped.</p>
<p>If you install the PerceptualDiff program (<a class="reference external" href="http://pdiff.sourceforge.net/">http://pdiff.sourceforge.net/</a>) and
it is in the path, then the autotest will attempt to use it as a last fallback
when comparing images. If images are found to be &#8220;perceptually&#8221; the same the
test will pass with the message &#8220;result images perceptually match, though
files differ.&#8221; This can dramatically cut down the number of apparent failures
that on close inspection are for all intents and purposes identical. Building
PerceptualDiff is a bit of a hassle and it will miss some significant
differences so it&#8217;s use is of mixed value.</p>
<p>For non-image results, such as xml and html output, the special image
comparisons are skipped.</p>
</div>
<div class="section" id="requires-handling-build-options">
<h2><a class="toc-backref" href="#table-of-contents">REQUIRES - Handling Build Options</a><a class="headerlink" href="#requires-handling-build-options" title="Permalink to this headline">¶</a></h2>
<p>Because MapServer can be built with many possible extensions, such as support
for OGR, GDAL, and PROJ.4, it is desirable to have the testsuite automatically
detect which tests should be run based on the configuratio of MapServer. This
is accomplished by capturing the version output of &#8220;shp2img -v&#8221; and using the
various keys in that to decide which tests can be run. A directory can have a
file called &#8220;all_require.txt&#8221; with a &#8220;REQUIRES:&#8221; line indicating components
required for all tests in the directory. If any of these requirements are not
met, no tests at all will be run in this directory. For instance, the
gdal/all_require.txt lists:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>REQUIRES: INPUT=GDAL OUTPUT=PNG
</pre></div>
</div>
<p>In addition, individual .map files can have additional requirements expressed
as a REQUIRES: comment in the mapfile. If the requirements are not met the map
will be skipped (and listed in the summary as a skipped test). For example
gdal/256_overlay_res.map has the following line to indicate it requires
projection support (in addition to the INPUT=GDAL and OUTPUT=PNG required by
all files in the directory):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># REQUIRES: SUPPORTS=PROJ</span>
</pre></div>
</div>
</div>
<div class="section" id="run-parms-tests-not-using-shp2img">
<h2><a class="toc-backref" href="#table-of-contents">RUN_PARMS: Tests not using shp2img</a><a class="headerlink" href="#run-parms-tests-not-using-shp2img" title="Permalink to this headline">¶</a></h2>
<p>There is also a RUN_PARMS keyword that may be placed in map files to override
a bunch of behaviour. The default behaviour is to process map files with
shp2img, but other programs such as mapserv or scalebar can be requested, and
various commandline arguments altered as well as the name of the output file.
For instance, the following line in misc/tr_scalebar.map indicates that the
output file should be called tr_scalebar.png, the commandline should look like
&#8220;[SCALEBAR] [MAPFILE] [RESULT]&#8221; instead of the default &#8220;[SHP2IMG] -m [MAPFILE]
-o [RESULT]&#8221;.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>RUN_PARMS: tr_scalebar.png [SCALEBAR] [MAPFILE] [RESULT]
</pre></div>
</div>
<p>For testing things as they would work from an HTTP request, use the RUN_PARMS
with the program [MAPSERV] and the QUERY_STRING argument, with results
redirected to a file.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># RUN_PARMS: wcs_cap.xml [MAPSERV] QUERY_STRING=&#39;map=[MAPFILE]&amp;SERVICE=WCS&amp;VERSION=1.0.0&amp;REQUEST=GetCapabilities&#39; &gt; [RESULT]</span>
</pre></div>
</div>
<p>For web services that generate images that would normally be prefixed with the
Content-type header, use [RESULT_NOMIME] to instruct the test harnass to
script off any http headers before doing the comparison.  This is particularly
valuable for image results so the files can be compared using special image
comparisons.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># Generate simple PNG.</span>
<span class="c1"># RUN_PARMS: wcs_simple.png [MAPSERV] QUERY_STRING=&#39;map=[MAPFILE]&amp;SERVICE=WCS&amp;VERSION=1.0.0&amp;REQUEST=GetCoverage&amp;WIDTH=120&amp;HEIGHT=90&amp;FORMAT=GDPNG&amp;BBOX=0,0,400,300&amp;COVERAGE=grey&amp;CRS=EPSG:32611&#39; &gt; [RESULT_DEMIME]</span>
</pre></div>
</div>
</div>
<div class="section" id="result-file-preprocessing">
<h2><a class="toc-backref" href="#table-of-contents">Result File Preprocessing</a><a class="headerlink" href="#result-file-preprocessing" title="Permalink to this headline">¶</a></h2>
<p>As mentioned above the [RESULT_DEMIME] directive can be used for image file
output from web services (ie. WMS GetMap requests).</p>
<p>For text, XML and HTML output it can also be helpful to apply other
pre-processing to the output file to make comparisons easlier.   The
[RESULT_DEVERSION] directive in the RUN_PARMS will apply several translations
to the output file including:</p>
<ul class="simple">
<li>stripping out the MapServer version string which changes depending on build
options and version.</li>
<li>manipulating the format of exponential numbers to be consistent across
platforms (changes windows e+0nn format to e+nn).</li>
<li>strip the last decimal place off floating point numbers to avoid
unnecessary sensitivity to platform specific number handling.</li>
<li>blank out timestamps to avoid &#8220;current time&#8221; sensitivity.</li>
</ul>
<p>In some cases it is also helpful to strip out lines matching a particular
pattern.  The [STRIP:xxx] directive drops all lines containing the indicated
substring.  Multiple [STRIP:xxx] directives may be included in the command
string if desired.  For instance, the error reports from the runtime
substitution validation test (misc/runtime_sub.map) produces error messages
with an absolute path in them which changes for each person.  The following
directive will drop any text lines in the result that contain the string
ShapefileOpen, which will be error messages in this case:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span># RUN_PARMS: runtime_sub_test001.txt [MAPSERV] QUERY_STRING=&#39;map=[MAPFILE]
&amp;mode=map&amp;layer=layer1&amp;name1=bdry_counpy2&#39; &gt; [RESULT_DEVERSION] [STRIP:ShapefileOpen]
</pre></div>
</div>
</div>
<div class="section" id="what-if-a-test-fails">
<h2><a class="toc-backref" href="#table-of-contents">What If A Test Fails?</a><a class="headerlink" href="#what-if-a-test-fails" title="Permalink to this headline">¶</a></h2>
<p>When running the test suite, it is common for some tests to fail depending on
vagaries of floating point on the platform, or harmless changes in
MapServer. To identify these compare the results in result with the file in
expected and determine what the differences are. If there is just a slight
shift in text or other features it is likely due to floating point differences
on different platforms. These can be ignored. If something has gone seriously
wrong, then track down the problem!</p>
<p>It is also prudent to avoid using output image formats that are platform
specific. For instance, if you produce TIFF it will generate big endian on big
endian systems and therefore be different at the binary level from what was
expected. PNG should be pretty safe.</p>
</div>
<div class="section" id="todo">
<h2><a class="toc-backref" href="#table-of-contents">TODO</a><a class="headerlink" href="#todo" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Add lots of tests for different stuff!  Very little vector testing done yet.</li>
<li>Add a high level script in the msautotest directory that runs the subscripts
in all the subdirectories and produces a summary report.</li>
<li>Add something to run tests on the server and report on changes.</li>
</ul>
</div>
<div class="section" id="adding-new-tests">
<h2><a class="toc-backref" href="#table-of-contents">Adding New Tests</a><a class="headerlink" href="#adding-new-tests" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Pick an appropriate directory to put the test in. Feel free to start a new
one for new families of testing functionality.</li>
<li>Create a minimal map file to test a particular issue. I would discourage
starting from a &#8220;real&#8221; mapfile and cutting down as it is hard to reduce this
to the minimum.</li>
<li>Give the new mapfile a name that hints at what it is testing without making
the name too long. For instance &#8220;ogr_join.map&#8221; tests OGR joins.
&#8220;rgb_overlay_res_to8bit.map&#8221; tests RGB overlay layers with resampling and
converting to 8bit output.</li>
<li>Put any MapServer functionality options in a # REQUIRES: item in the header
as described in the internal functioning topic above.</li>
<li>Write some comments at the top of the .map file on what this test is
intended to check.</li>
<li>Add any required datasets within the data directory beneath the test
directory. These test datasets should be as small as possible! Reuse
existing datasets if at all possible.</li>
<li>run the &#8220;run_tests.py&#8221; script.</li>
<li>verify that the newly created expected/&lt;testname&gt;.png file produces the
results you expect. If not, revise the map and rerun the test, now checking
the results/&lt;testname&gt;.png file. Move the results/&lt;testname&gt;.png file into
the expected directory when you are happy with it.</li>
<li>add the .map file, and the expected/&lt;testname&gt;.png file to the
repository when you are happy with them.  For example,</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span>% git add mynewtest.map expected/mynewtest.png
% git commit -m &quot;My new test&quot; mynewtest.map expected/mynewtest.png
</pre></div>
</div>
<p>You&#8217;re done!</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3>Navigation</h3>
<p>
<a href="../../about.html" title="About">About</a><br>
<a href="../../products.html" title="Products">Products</a><br>
<a href="../../community/index.html" title="Community">Community</a><br>
<a href="../index.html" title="Development">Development</a><br>
<a href="../../download.html" title="Downloads">Downloads</a><br>
<a href="../../documentation.html" title="Documentation">Documentation</a><br>
<a href="../../faq.html" title="FAQ">FAQ</a>
</p>
  <h3>Current Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Regression Testing</a><ul>
<li><a class="reference internal" href="#getting-msautotest">Getting <cite>msautotest</cite></a></li>
<li><a class="reference internal" href="#running-msautotest">Running msautotest</a></li>
<li><a class="reference internal" href="#checking-failures">Checking Failures</a></li>
<li><a class="reference internal" href="#background">Background</a></li>
<li><a class="reference internal" href="#result-comparisons">Result Comparisons</a></li>
<li><a class="reference internal" href="#requires-handling-build-options">REQUIRES - Handling Build Options</a></li>
<li><a class="reference internal" href="#run-parms-tests-not-using-shp2img">RUN_PARMS: Tests not using shp2img</a></li>
<li><a class="reference internal" href="#result-file-preprocessing">Result File Preprocessing</a></li>
<li><a class="reference internal" href="#what-if-a-test-fails">What If A Test Fails?</a></li>
<li><a class="reference internal" href="#todo">TODO</a></li>
<li><a class="reference internal" href="#adding-new-tests">Adding New Tests</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Open Source Geospatial Foundation.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.3.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.4</a>
      
    </div>

    

    
  </body>
</html>